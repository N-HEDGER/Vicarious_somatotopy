{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform connective field fitting on HCP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from vicsompy.surface import Subsurface\n",
    "import numpy as np\n",
    "from vicsompy.modeling import MssCf\n",
    "from vicsompy.surface import CiftiHandler\n",
    "from vicsompy.subject import HcpSubject"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise HcpSubject class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sub = HcpSubject(subject='999999',experiment_id='movie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for performing connective field modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_subject(expt_id,csub,analysis_name='TEST'):\n",
    "    my_sub=HcpSubject(subject=csub, experiment_id=expt_id) # Initialise subject\n",
    "\n",
    "    my_sub.prep_data() # Prep data paths\n",
    "    my_sub.import_data() # Import data\n",
    "    my_sub.prepare_out_dirs(analysis_name) # Prepare output directories\n",
    "\n",
    "    data_train=my_sub.brainmodel.decompose_data(my_sub.all_data.T) # Decompose data into surface and subcortical components.\n",
    "    data_test=my_sub.brainmodel.decompose_data(my_sub.concatenated_test_sequence.T) # Decompose data into surface and subcortical components.\n",
    "\n",
    "    nm=MssCf(my_sub,analysis_name=analysis_name) # Initialise sensory_dm object\n",
    "    nm.make_subsurfaces() # Make subsurfaces\n",
    "\n",
    "    nm.make_dm(np.nan_to_num(data_train[0])) # Make design matrix.\n",
    "    nm.prep_pipeline(run_durations=my_sub.run_onsets) # Prepare ridge regression pipeline, specifying run durations for cross-validation.\n",
    "    nm.fit(np.nan_to_num(my_sub.all_data.T)) # Fit model.\n",
    "    nm.get_params() # Get parameters.\n",
    "    nm.test_xval(np.nan_to_num(data_test[0]),np.nan_to_num(my_sub.concatenated_test_sequence.T)) # Test model on held-out data.\n",
    "    \n",
    "    nm.save_outcomes() # Save outcomes.\n",
    "    \n",
    "    nm.load_lookups() # Load lookup tables for each subsurface.\n",
    "    nm.load_precomputed_betas() # Load precomputed betas.\n",
    "    nm.reconstruct_profiles() # Reconstruct profiles via dot product of lookup tables and betas.\n",
    "    nm.splice_lookups() # Splice lookups via dot product of lookup tables and CF profiles\n",
    "    nm.save_spliced_lookups() # Saveout these spliced lookups.\n",
    "    \n",
    "    nm.prepare_frame(with_spliced=True) # Prepare dataframe of outcomes.\n",
    "    nm.test_null_model(np.nan_to_num(data_test[0]),my_sub.concatenated_test_sequence) # Also test null model.\n",
    "    nm.save_frame() # Save dataframe of outcomes\n",
    "    \n",
    "    return csub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the fitting on the movie subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_fits=[analyse_subject('movie',str(sub),analysis_name='TEST') for sub in my_sub.full_data_subjects]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the fitting on the resting state subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_fits=[analyse_subject('rs',str(sub),analysis_name='TEST_REST') for sub in my_sub.full_data_subjects]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also do fitting on the timecourse average subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_fit=analyse_subject('movie','999999',analysis_name='TEST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also do fitting on subject and movie splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_subjects=['subsplit_1','subsplit_2','movsplit_1','movsplit_2']\n",
    "\n",
    "split_fits=[analyse_subject('movie',sub,analysis_name='TEST') for sub in split_subjects]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2becd74a87a4634fe3ae5ad538ef48e1372c4bfc930a488ee945fd34dcf4760"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
